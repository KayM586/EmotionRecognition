{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfer Learning with VGG16 WITHOUT Augmentation/Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pylab as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from PIL import Image\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.regularizers import l2\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/kaylienguyen/Downloads/FER_dataset/trainrevised/angry/Training_35668808.jpg',\n",
       " '/Users/kaylienguyen/Downloads/FER_dataset/trainrevised/disgust/Training_2580532.jpg',\n",
       " '/Users/kaylienguyen/Downloads/FER_dataset/trainrevised/fear/Training_19995150.jpg',\n",
       " '/Users/kaylienguyen/Downloads/FER_dataset/trainrevised/happy/Training_50449107.jpg',\n",
       " '/Users/kaylienguyen/Downloads/FER_dataset/trainrevised/neutral/Training_27707774.jpg',\n",
       " '/Users/kaylienguyen/Downloads/FER_dataset/trainrevised/sad/Training_86437620.jpg',\n",
       " '/Users/kaylienguyen/Downloads/FER_dataset/trainrevised/surprise/Training_53079763.jpg']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "testEmotions = '/Users/kaylienguyen/Downloads/FER_dataset/testrevised'\n",
    "trainEmotions = '/Users/kaylienguyen/Downloads/FER_dataset/trainrevised'\n",
    "image_directories_test = [\n",
    "    os.path.join(testEmotions, \"angry\"),\n",
    "    os.path.join(testEmotions, \"disgust\"),\n",
    "    os.path.join(testEmotions, \"fear\"),\n",
    "    os.path.join(testEmotions, \"happy\"),\n",
    "    os.path.join(testEmotions, \"neutral\"),\n",
    "    os.path.join(testEmotions, \"sad\"),\n",
    "    os.path.join(testEmotions, \"surprise\")\n",
    "]\n",
    "image_directories_train = [\n",
    "    os.path.join(trainEmotions, \"angry\"),\n",
    "    os.path.join(trainEmotions, \"disgust\"),\n",
    "    os.path.join(trainEmotions, \"fear\"),\n",
    "    os.path.join(trainEmotions, \"happy\"),\n",
    "    os.path.join(trainEmotions, \"neutral\"),\n",
    "    os.path.join(trainEmotions, \"sad\"),\n",
    "    os.path.join(trainEmotions, \"surprise\")\n",
    "]\n",
    "\n",
    "def get_first_image(directory):\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            return os.path.join(directory, filename)\n",
    "        \n",
    "train_images = [get_first_image(directory) for directory in image_directories_train]\n",
    "display(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnidentifiedImageError",
     "evalue": "cannot identify image file '/Users/kaylienguyen/Downloads/FER_dataset/trainrevised/angry/Training_35668808.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(train_images)):\n\u001b[1;32m      5\u001b[0m     ax \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplot(\u001b[39m2\u001b[39m, \u001b[39m7\u001b[39m, i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m     image \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mopen(train_images[i])\n\u001b[1;32m      7\u001b[0m     plt\u001b[39m.\u001b[39mimshow(image)\n\u001b[1;32m      8\u001b[0m     plt\u001b[39m.\u001b[39mgray()\n",
      "File \u001b[0;32m~/miniconda3/envs/ann/lib/python3.11/site-packages/PIL/Image.py:3309\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3307\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(message)\n\u001b[1;32m   3308\u001b[0m msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcannot identify image file \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (filename \u001b[39mif\u001b[39;00m filename \u001b[39melse\u001b[39;00m fp)\n\u001b[0;32m-> 3309\u001b[0m \u001b[39mraise\u001b[39;00m UnidentifiedImageError(msg)\n",
      "\u001b[0;31mUnidentifiedImageError\u001b[0m: cannot identify image file '/Users/kaylienguyen/Downloads/FER_dataset/trainrevised/angry/Training_35668808.jpg'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 4800x4800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#show a training image from each category\n",
    "\n",
    "plt.figure(figsize=(48, 48))\n",
    "for i in range(len(train_images)):\n",
    "    ax = plt.subplot(2, 7, i + 1)\n",
    "    image = Image.open(train_images[i])\n",
    "    plt.imshow(image)\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    emotion_label = train_images[i].split(\"/\")[-2]\n",
    "    \n",
    "    plt.text(0.5, -0.1, emotion_label, horizontalalignment='center', fontsize=25, transform=ax.transAxes)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train images: 28614\n",
      "Number of test images: 7071\n"
     ]
    }
   ],
   "source": [
    "#pre-processing\n",
    "\n",
    "def get_image_paths_and_labels(image_directories):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "\n",
    "    for i, directory in enumerate(image_directories):\n",
    "        emotion_label = os.path.basename(directory)\n",
    "        for filename in os.listdir(directory):\n",
    "            if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "                image_paths.append(os.path.join(directory, filename))\n",
    "                labels.append(emotion_label)\n",
    "\n",
    "    return image_paths, labels\n",
    "\n",
    "train_image_paths, train_labels = get_image_paths_and_labels(image_directories_train)\n",
    "test_image_paths, test_labels = get_image_paths_and_labels(image_directories_test)\n",
    "\n",
    "print(\"Number of train images:\", len(train_image_paths))\n",
    "print(\"Number of test images:\", len(test_image_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_images(image_paths, img_width, img_height):\n",
    "    images = []\n",
    "    for img_path in image_paths:\n",
    "        img = load_img(img_path, target_size=(img_width, img_height))\n",
    "        img_array = img_to_array(img)\n",
    "        images.append(img_array)\n",
    "    return np.array(images)\n",
    "\n",
    "img_width = 48\n",
    "img_height = 48\n",
    "\n",
    "X_train = load_and_preprocess_images(train_image_paths, img_width, img_height)\n",
    "X_test = load_and_preprocess_images(test_image_paths, img_width, img_height)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the labels for training data\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "test_labels_encoded = label_encoder.transform(test_labels)\n",
    "\n",
    "# Convert the encoded labels to one-hot encoded vectors\n",
    "y_train = to_categorical(train_labels_encoded)\n",
    "y_test = to_categorical(test_labels_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (img_width, img_height, 3)\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "conv_base = VGG16(weights='imagenet',\n",
    "                include_top=False,\n",
    "                input_shape=(48, 48, 3))\n",
    "conv_base.trainable = False\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(filters=10, kernel_size=3, strides=(1, 1), padding='valid', activation='relu', input_shape=input_shape, kernel_regularizer=l2(.01)),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=2),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(filters=20, kernel_size=3, strides=(1, 1), padding='valid', activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=2),\n",
    "    BatchNormalization(),\n",
    "    #Conv2D(filters=128, kernel_size=3, strides=(1, 1), padding='valid', activation='relu'),\n",
    "    #Conv2D(filters=256, kernel_size=3, strides=(1, 1), padding='valid', activation='relu'),\n",
    "    #Conv2D(filters=256, kernel_size=3, strides=(1, 1), padding='valid', activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(1024, activation = 'relu'),\n",
    "    Dense(512, activation = 'relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    Dense(7, activation='softmax')\n",
    "])\n",
    "\n",
    "# model.compile(\n",
    "#     optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "#     loss='categorical_crossentropy',\n",
    "#     metrics=['categorical_accuracy']\n",
    "# )\n",
    "\n",
    "conv_base.trainable = True\n",
    "set_trainable = False\n",
    "for layer in conv_base.layers:\n",
    "    if layer.name == 'block5_conv1':\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "716/716 [==============================] - 32s 44ms/step - loss: 0.5334 - accuracy: 0.8230 - val_loss: 21.3872 - val_accuracy: 0.0874 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "716/716 [==============================] - 35s 49ms/step - loss: 0.4252 - accuracy: 0.8690 - val_loss: 25.8823 - val_accuracy: 0.0771 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "716/716 [==============================] - 31s 43ms/step - loss: 0.3250 - accuracy: 0.9063 - val_loss: 30.0194 - val_accuracy: 0.0657 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "716/716 [==============================] - 31s 43ms/step - loss: 0.2557 - accuracy: 0.9286 - val_loss: 39.8229 - val_accuracy: 0.0444 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "716/716 [==============================] - 34s 47ms/step - loss: 0.1111 - accuracy: 0.9754 - val_loss: 38.2161 - val_accuracy: 0.0793 - lr: 2.0000e-04\n",
      "Epoch 6/10\n",
      "716/716 [==============================] - 32s 44ms/step - loss: 0.0542 - accuracy: 0.9905 - val_loss: 43.7157 - val_accuracy: 0.0949 - lr: 2.0000e-04\n",
      "Epoch 7/10\n",
      "716/716 [==============================] - 32s 45ms/step - loss: 0.0431 - accuracy: 0.9948 - val_loss: 46.8878 - val_accuracy: 0.1001 - lr: 2.0000e-04\n",
      "Epoch 8/10\n",
      "716/716 [==============================] - 36s 50ms/step - loss: 0.0373 - accuracy: 0.9970 - val_loss: 50.2578 - val_accuracy: 0.0821 - lr: 4.0000e-05\n",
      "Epoch 9/10\n",
      "716/716 [==============================] - 34s 47ms/step - loss: 0.0329 - accuracy: 0.9970 - val_loss: 50.3127 - val_accuracy: 0.0875 - lr: 4.0000e-05\n",
      "Epoch 10/10\n",
      "716/716 [==============================] - 33s 46ms/step - loss: 0.0322 - accuracy: 0.9973 - val_loss: 51.6481 - val_accuracy: 0.0874 - lr: 4.0000e-05\n",
      "221/221 [==============================] - 2s 8ms/step - loss: 13.9324 - accuracy: 0.4254\n",
      "Test Loss:  13.93237590789795\n",
      "Test Accuracy: 0.425399512052536\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "initial_learning_rate = 1e-4\n",
    "\n",
    "# Define a learning rate scheduler\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor='val_loss',   \n",
    "    factor=0.2,           \n",
    "    patience=3,           \n",
    "    min_lr=1e-6           \n",
    ")\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(lr=initial_learning_rate),  \n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[lr_scheduler]  \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "#model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=optimizers.Adam(lr=1e-4))\n",
    "#model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2)\n",
    "\n",
    "#early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "#model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2, callbacks=[early_stopping])\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print('Test Loss: ', test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ann",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
