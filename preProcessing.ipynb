{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pylab as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from PIL import Image\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.regularizers import l2\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255, zoom_range=0.3, horizontal_flip=True)\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "TRAIN_DATA_PATH = '/Users/kaylienguyen/Downloads/FER_dataset/trainrevised'\n",
    "TEST_DATA_PATH = '/Users/kaylienguyen/Downloads/FER_dataset/testrevised'\n",
    "IMAGE_SIZE = (48, 48)\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28614 images belonging to 7 classes.\n",
      "Found 7071 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DATA_PATH,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical',\n",
    "    shuffle=True)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    TEST_DATA_PATH,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical',\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (48, 48, 1)\n",
    "epochs = 40\n",
    "conv_base = VGG16(weights='imagenet',\n",
    "                include_top=False,\n",
    "                input_shape=(48, 48, 3))\n",
    "conv_base.trainable = False\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(filters=10, kernel_size=3, strides=(1, 1), padding='valid', activation='relu', input_shape=input_shape, kernel_regularizer=l2(.01)),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=2),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(filters=20, kernel_size=3, strides=(1, 1), padding='valid', activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=2),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(filters=128, kernel_size=3, strides=(1, 1), padding='valid', activation='relu'),\n",
    "    #Conv2D(filters=256, kernel_size=3, strides=(1, 1), padding='valid', activation='relu'),\n",
    "    #Conv2D(filters=256, kernel_size=3, strides=(1, 1), padding='valid', activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(1024, activation = 'relu'),\n",
    "    Dense(512, activation = 'relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    Dense(7, activation='softmax')\n",
    "])\n",
    "\n",
    "conv_base.trainable = True\n",
    "set_trainable = False\n",
    "for layer in conv_base.layers:\n",
    "    if layer.name == 'block5_conv1':\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "448/448 [==============================] - 43s 93ms/step - loss: 1.7355 - accuracy: 0.3064 - val_loss: 1.6400 - val_accuracy: 0.3596\n",
      "Epoch 2/40\n",
      "448/448 [==============================] - 42s 93ms/step - loss: 1.5427 - accuracy: 0.4036 - val_loss: 1.4750 - val_accuracy: 0.4418\n",
      "Epoch 3/40\n",
      "448/448 [==============================] - 43s 96ms/step - loss: 1.4492 - accuracy: 0.4438 - val_loss: 1.3919 - val_accuracy: 0.4687\n",
      "Epoch 4/40\n",
      "448/448 [==============================] - 43s 95ms/step - loss: 1.3745 - accuracy: 0.4768 - val_loss: 1.3649 - val_accuracy: 0.4774\n",
      "Epoch 5/40\n",
      "448/448 [==============================] - 44s 97ms/step - loss: 1.3337 - accuracy: 0.4967 - val_loss: 1.2767 - val_accuracy: 0.5112\n",
      "Epoch 6/40\n",
      "448/448 [==============================] - 44s 98ms/step - loss: 1.2838 - accuracy: 0.5177 - val_loss: 1.3678 - val_accuracy: 0.4885\n",
      "Epoch 7/40\n",
      "448/448 [==============================] - 45s 100ms/step - loss: 1.2571 - accuracy: 0.5259 - val_loss: 1.2738 - val_accuracy: 0.5218\n",
      "Epoch 8/40\n",
      "448/448 [==============================] - 45s 101ms/step - loss: 1.2241 - accuracy: 0.5436 - val_loss: 1.3379 - val_accuracy: 0.4930\n",
      "Epoch 9/40\n",
      "448/448 [==============================] - 45s 100ms/step - loss: 1.2019 - accuracy: 0.5468 - val_loss: 1.4047 - val_accuracy: 0.4794\n",
      "Epoch 10/40\n",
      "448/448 [==============================] - 45s 101ms/step - loss: 1.1751 - accuracy: 0.5588 - val_loss: 1.3118 - val_accuracy: 0.4988\n",
      "Epoch 11/40\n",
      "448/448 [==============================] - 45s 101ms/step - loss: 1.1510 - accuracy: 0.5699 - val_loss: 1.3496 - val_accuracy: 0.4934\n",
      "Epoch 12/40\n",
      "448/448 [==============================] - 46s 103ms/step - loss: 1.1366 - accuracy: 0.5720 - val_loss: 1.3028 - val_accuracy: 0.5172\n",
      "Epoch 13/40\n",
      "448/448 [==============================] - 44s 99ms/step - loss: 1.1198 - accuracy: 0.5819 - val_loss: 1.2046 - val_accuracy: 0.5500\n",
      "Epoch 14/40\n",
      "448/448 [==============================] - 43s 97ms/step - loss: 1.0969 - accuracy: 0.5929 - val_loss: 1.1576 - val_accuracy: 0.5692\n",
      "Epoch 15/40\n",
      "448/448 [==============================] - 45s 100ms/step - loss: 1.0841 - accuracy: 0.5994 - val_loss: 1.2404 - val_accuracy: 0.5333\n",
      "Epoch 16/40\n",
      "448/448 [==============================] - 46s 102ms/step - loss: 1.0613 - accuracy: 0.6060 - val_loss: 1.1878 - val_accuracy: 0.5612\n",
      "Epoch 17/40\n",
      "448/448 [==============================] - 46s 104ms/step - loss: 1.0398 - accuracy: 0.6127 - val_loss: 1.1602 - val_accuracy: 0.5681\n",
      "Epoch 18/40\n",
      "448/448 [==============================] - 42s 94ms/step - loss: 1.0219 - accuracy: 0.6261 - val_loss: 1.5947 - val_accuracy: 0.4414\n",
      "Epoch 19/40\n",
      "448/448 [==============================] - 45s 100ms/step - loss: 1.0038 - accuracy: 0.6299 - val_loss: 1.4810 - val_accuracy: 0.4627\n",
      "Epoch 20/40\n",
      "448/448 [==============================] - 43s 96ms/step - loss: 0.9853 - accuracy: 0.6391 - val_loss: 1.2493 - val_accuracy: 0.5551\n",
      "Epoch 21/40\n",
      "448/448 [==============================] - 41s 91ms/step - loss: 0.9766 - accuracy: 0.6441 - val_loss: 1.1729 - val_accuracy: 0.5794\n",
      "Epoch 22/40\n",
      "448/448 [==============================] - 42s 94ms/step - loss: 0.9521 - accuracy: 0.6533 - val_loss: 1.3284 - val_accuracy: 0.5374\n",
      "Epoch 23/40\n",
      "448/448 [==============================] - 41s 91ms/step - loss: 0.9366 - accuracy: 0.6561 - val_loss: 1.2012 - val_accuracy: 0.5725\n",
      "Epoch 24/40\n",
      "448/448 [==============================] - 41s 91ms/step - loss: 0.9220 - accuracy: 0.6654 - val_loss: 1.2090 - val_accuracy: 0.5745\n",
      "Epoch 25/40\n",
      "448/448 [==============================] - 41s 92ms/step - loss: 0.8991 - accuracy: 0.6760 - val_loss: 1.3892 - val_accuracy: 0.5214\n",
      "Epoch 26/40\n",
      "448/448 [==============================] - 41s 91ms/step - loss: 0.8855 - accuracy: 0.6827 - val_loss: 1.6214 - val_accuracy: 0.4830\n",
      "Epoch 27/40\n",
      "448/448 [==============================] - 41s 92ms/step - loss: 0.8642 - accuracy: 0.6874 - val_loss: 1.3229 - val_accuracy: 0.5545\n",
      "Epoch 28/40\n",
      "448/448 [==============================] - 41s 90ms/step - loss: 0.8565 - accuracy: 0.6961 - val_loss: 1.2924 - val_accuracy: 0.5585\n",
      "Epoch 29/40\n",
      "448/448 [==============================] - 41s 91ms/step - loss: 0.8398 - accuracy: 0.6977 - val_loss: 1.3238 - val_accuracy: 0.5552\n",
      "Epoch 30/40\n",
      "448/448 [==============================] - 41s 91ms/step - loss: 0.8168 - accuracy: 0.7091 - val_loss: 1.3422 - val_accuracy: 0.5534\n",
      "Epoch 31/40\n",
      "448/448 [==============================] - 41s 91ms/step - loss: 0.8096 - accuracy: 0.7118 - val_loss: 1.3503 - val_accuracy: 0.5595\n",
      "Epoch 32/40\n",
      "448/448 [==============================] - 41s 91ms/step - loss: 0.7866 - accuracy: 0.7188 - val_loss: 1.2509 - val_accuracy: 0.5820\n",
      "Epoch 33/40\n",
      "448/448 [==============================] - 42s 93ms/step - loss: 0.7781 - accuracy: 0.7234 - val_loss: 1.3321 - val_accuracy: 0.5626\n",
      "Epoch 34/40\n",
      "448/448 [==============================] - 41s 91ms/step - loss: 0.7589 - accuracy: 0.7294 - val_loss: 1.2449 - val_accuracy: 0.5930\n",
      "Epoch 35/40\n",
      "448/448 [==============================] - 42s 94ms/step - loss: 0.7430 - accuracy: 0.7382 - val_loss: 1.3297 - val_accuracy: 0.5692\n",
      "Epoch 36/40\n",
      "448/448 [==============================] - 42s 94ms/step - loss: 0.7310 - accuracy: 0.7387 - val_loss: 1.2620 - val_accuracy: 0.5957\n",
      "Epoch 37/40\n",
      "448/448 [==============================] - 41s 91ms/step - loss: 0.7170 - accuracy: 0.7515 - val_loss: 1.2513 - val_accuracy: 0.5892\n",
      "Epoch 38/40\n",
      "448/448 [==============================] - 42s 93ms/step - loss: 0.7026 - accuracy: 0.7541 - val_loss: 1.3415 - val_accuracy: 0.5837\n",
      "Epoch 39/40\n",
      "448/448 [==============================] - 46s 103ms/step - loss: 0.6896 - accuracy: 0.7567 - val_loss: 1.3031 - val_accuracy: 0.5861\n",
      "Epoch 40/40\n",
      "448/448 [==============================] - 42s 94ms/step - loss: 0.6682 - accuracy: 0.7659 - val_loss: 1.3582 - val_accuracy: 0.5865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3m/hxyrmk3x0fndxrfylccz8ldh0000gn/T/ipykernel_98249/2145479792.py:40: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  test_loss, test_accuracy = model.evaluate_generator(test_generator)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss:  1.3581846952438354\n",
      "Test Accuracy: 0.5864799618721008\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=optimizers.Adam(lr=1e-4))\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    validation_data = test_generator  \n",
    ")\n",
    "\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate_generator(test_generator)\n",
    "print('Test Loss: ', test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ann",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
